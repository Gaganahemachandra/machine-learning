{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ../data/MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ../data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../data/MNIST/\"\n",
    "data = input_data.read_data_sets(DATA_DIR, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 22672\r\n",
      "-rw-r--r--  1 abulbasar  staff  1648877 Sep 14 00:08 t10k-images-idx3-ubyte.gz\r\n",
      "-rw-r--r--  1 abulbasar  staff     4542 Sep 14 00:08 t10k-labels-idx1-ubyte.gz\r\n",
      "-rw-r--r--  1 abulbasar  staff  9912422 Sep 14 00:08 train-images-idx3-ubyte.gz\r\n",
      "-rw-r--r--  1 abulbasar  staff    28881 Sep 14 00:08 train-labels-idx1-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data/MNIST/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.87%\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 1000\n",
    "MINIBATCH_SIZE = 100\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "y_pred = tf.matmul(x, W)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels= y_true))\n",
    "\n",
    "gd_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "#gd_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Train\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(NUM_STEPS):\n",
    "        batch_xs, batch_ys = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict={x: batch_xs, y_true: batch_ys})\n",
    "\n",
    "    # Test\n",
    "    ans = sess.run(accuracy, feed_dict={x: data.test.images, y_true: data.test.labels})\n",
    "    \n",
    "\n",
    "print(\"Accuracy: {:.4}%\".format(ans*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_layer(input, shape):\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input, W) + b)\n",
    "\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = weight_variable([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "conv1 = conv_layer(x_image, shape=[5, 5, 1, 32])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "conv2 = conv_layer(conv1_pool, shape=[5, 5, 32, 64])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1, 7*7*64])\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.07999999821186066\n",
      "step 100, training accuracy 0.7799999713897705\n",
      "step 200, training accuracy 0.9599999785423279\n",
      "step 300, training accuracy 0.9200000166893005\n",
      "step 400, training accuracy 0.9200000166893005\n",
      "step 500, training accuracy 0.9599999785423279\n",
      "step 600, training accuracy 1.0\n",
      "step 700, training accuracy 0.9800000190734863\n",
      "step 800, training accuracy 1.0\n",
      "step 900, training accuracy 0.9399999976158142\n",
      "test accuracy: 0.9671999216079712\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels= y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(NUM_STEPS):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: batch[0], y_: batch[1],\n",
    "                                                           keep_prob: 1.0})\n",
    "            print(\"step {}, training accuracy {}\".format(i, train_accuracy))\n",
    "\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    X = mnist.test.images.reshape(10, 1000, 784)\n",
    "    Y = mnist.test.labels.reshape(10, 1000, 10)\n",
    "    test_accuracy = np.mean([sess.run(accuracy, \n",
    "                             feed_dict={x:X[i], y_:Y[i],keep_prob:1.0}) \n",
    "                             for i in range(10)])\n",
    "\n",
    "print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
